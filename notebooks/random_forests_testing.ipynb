{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\coding\\Uni\\MA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\mambaforge-pypy3\\envs\\MA\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import librosa\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from evoaudio.population import Population\n",
    "from evoaudio.sample_library import SampleLibrary\n",
    "from evoaudio.feature_extraction import extract_features_for_window, extract_features_for_windows\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population to feature vector of shape (n_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The following statistics are proposed as approximative features.  \n",
    "For each instrument and each onset in the approximated\n",
    "music track, we save the smallest distance between the best\n",
    "candidate mixture which contains this instrument and the onset\n",
    "to approximate.  \n",
    "(pop.best_collections_per_onset)  \n",
    "  \n",
    "These smallest distances are kept during the\n",
    "complete evolutionary loop in an archive and do not represent\n",
    "the final population only. (TODO!) \n",
    "    \n",
    "Then, we estimate the mean, the\n",
    "minimum, and the maximum values for each of 51 instrument\n",
    "and 88 theoretically possible pitches for two different analysis\n",
    "frames of 10s and 3s. Additionally, we sort the recognised\n",
    "instruments based on the smallest distances, and assign ranks\n",
    "to corresponding approximative features, e.g., value of “rang\n",
    "of acoustic guitar” = 1 means that acoustic guitar had the\n",
    "smallest mean distance between approximations with this\n",
    "instrument and unknown onsets in the analysis frame. This\n",
    "leads to an overall number of feature dimensions equal to\n",
    "(51 · 3 + 88 · 3 + 51) · 2 = 936.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading samples: 100%|██████████| 6478/6478 [00:16<00:00, 403.26it/s]\n"
     ]
    }
   ],
   "source": [
    "pop = Population.from_file(\"30k_gen_nutcracker.pkl\")\n",
    "target, sr = librosa.load(librosa.ex('nutcracker'), duration=30)\n",
    "lib = SampleLibrary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 features generated from 50 instruments and 89 pitches.\n"
     ]
    }
   ],
   "source": [
    "## Choose two different analysis frames of 10s and 3s\n",
    "end_offset = 10 * sr\n",
    "possible_onsets = len(target) - end_offset\n",
    "window_start = np.random.randint(low=0, high=possible_onsets)\n",
    "window_end = window_start + end_offset\n",
    "\n",
    "## Grab the onsets in those windows, and the associated best records from the population\n",
    "relevant_collections = [collection for collection in pop.best_collections_per_onset.values() if collection.onset in range(window_start, window_end)]\n",
    "\n",
    "## For each window separately, calculate the maximum, minimum, and mean fitnesses for each occasion of\n",
    "## An instrument\n",
    "instrument_occurrences_fitness = dict()\n",
    "## A pitch\n",
    "pitch_occurrences_fitness = dict()\n",
    "\n",
    "for collection in relevant_collections:\n",
    "    for sample in collection.samples:\n",
    "        if sample.instrument in instrument_occurrences_fitness:\n",
    "            instrument_occurrences_fitness[sample.instrument].append(collection.fitness)\n",
    "        else:\n",
    "            instrument_occurrences_fitness[sample.instrument] = [collection.fitness]\n",
    "        if sample.pitch in pitch_occurrences_fitness:\n",
    "            pitch_occurrences_fitness[sample.pitch].append(collection.fitness)\n",
    "        else:\n",
    "            pitch_occurrences_fitness[sample.pitch] = [collection.fitness]\n",
    "\n",
    "# print(instrument_occurrences_fitness)\n",
    "# print(pitch_occurrences_fitness)\n",
    "\n",
    "instrument_min = {instrument: np.min(instrument_occurrences_fitness[instrument]) for instrument in instrument_occurrences_fitness}\n",
    "instrument_max = {instrument: np.max(instrument_occurrences_fitness[instrument]) for instrument in instrument_occurrences_fitness}\n",
    "instrument_mean = {instrument: np.mean(instrument_occurrences_fitness[instrument]) for instrument in instrument_occurrences_fitness}\n",
    "\n",
    "pitch_min = {pitch: np.min(pitch_occurrences_fitness[pitch]) for pitch in pitch_occurrences_fitness}\n",
    "pitch_max = {pitch: np.max(pitch_occurrences_fitness[pitch]) for pitch in pitch_occurrences_fitness}\n",
    "pitch_mean = {pitch: np.mean(pitch_occurrences_fitness[pitch]) for pitch in pitch_occurrences_fitness}\n",
    "\n",
    "## Finally, give each instrument a rank from 1 to n_instruments, based on their mean distances (smallest = rank 1, highest = rank n_instruments)\n",
    "# instrument_sort = np.argsort([instrument_mean[instrument] for instrument in instrument_mean])\n",
    "instrument_sort = {k: v for k, v in sorted(instrument_mean.items(), key=lambda item: item[1])}\n",
    "instrument_ranks = {instrument: i + 1 for i, instrument in enumerate(instrument_sort)}\n",
    "\n",
    "# Create feature vector\n",
    "instrument_features = []\n",
    "for instrument_info in lib.instruments:\n",
    "    instr_name = instrument_info.name\n",
    "    if instr_name in instrument_ranks:\n",
    "        instrument_features.append([instrument_min[instr_name], instrument_mean[instr_name], instrument_max[instr_name], instrument_ranks[instr_name]])\n",
    "    else:\n",
    "        instrument_features.append([np.inf, np.inf, np.inf, np.inf])\n",
    "pitch_features = []\n",
    "for pitch in lib.pitches:\n",
    "    if pitch in pitch_min:\n",
    "        pitch_features.append([pitch_min[pitch], pitch_mean[pitch], pitch_max[pitch]])\n",
    "    else:\n",
    "        pitch_features.append([np.inf, np.inf, np.inf])\n",
    "flat_instr_features = np.array(instrument_features).flatten()\n",
    "flat_pitch_features = np.array(pitch_features).flatten()\n",
    "features = np.concatenate((flat_instr_features, flat_pitch_features))\n",
    "print(f\"{len(features)} features generated from {len(lib.instruments)} instruments and {len(lib.pitches)} pitches.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 features generated from 50 instruments and 89 pitches.\n"
     ]
    }
   ],
   "source": [
    "end_offset = 10 * sr\n",
    "possible_onsets = len(target) - end_offset\n",
    "window_start = np.random.randint(low=0, high=possible_onsets)\n",
    "window_end = window_start + end_offset\n",
    "features = extract_features_for_window(pop, lib, window_start, window_end)\n",
    "print(f\"{len(features)} features generated from {len(lib.instruments)} instruments and {len(lib.pitches)} pitches.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934 features generated from 50 instruments and 89 pitches.\n"
     ]
    }
   ],
   "source": [
    "features = extract_features_for_windows(pop=pop, lib=lib, window_lengths=[3, 10], n_total_samples=len(target), sr=sr)\n",
    "print(f\"{len(features)} features generated from {len(lib.instruments)} instruments and {len(lib.pitches)} pitches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X, y)\n",
    "print(clf.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c']\n"
     ]
    }
   ],
   "source": [
    "X = [[0], [1], [2]]\n",
    "y = [\"a\", \"b\", \"c\"]\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X, y)\n",
    "print(clf.predict([[2]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of Random Forests from Saved Populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading samples: 100%|██████████| 6826/6826 [00:09<00:00, 688.63it/s] \n"
     ]
    }
   ],
   "source": [
    "lib = SampleLibrary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 10k generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m      9\u001b[0m songnames \u001b[39m=\u001b[39m [file\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m popfiles]\n\u001b[0;32m     10\u001b[0m \u001b[39m# all_soundfiles = glob(\"./audio/1517-Artists/**/*.mp3\", recursive=True)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# soundfiles = []\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m# for name in songnames:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m#             break\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# lib = SampleLibrary()\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m pops \u001b[39m=\u001b[39m [Population\u001b[39m.\u001b[39mfrom_file(popfile\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mHip_Hop\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mHip-Hop\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mfor\u001b[39;00m popfile \u001b[39min\u001b[39;00m popfiles]\n\u001b[0;32m     19\u001b[0m \u001b[39m# songs = [librosa.load(soundfile)[0] for soundfile in soundfiles]\u001b[39;00m\n\u001b[0;32m     20\u001b[0m sr \u001b[39m=\u001b[39m \u001b[39m22050\u001b[39m\n",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m songnames \u001b[39m=\u001b[39m [file\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m popfiles]\n\u001b[0;32m     10\u001b[0m \u001b[39m# all_soundfiles = glob(\"./audio/1517-Artists/**/*.mp3\", recursive=True)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# soundfiles = []\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m# for name in songnames:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m#             break\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# lib = SampleLibrary()\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m pops \u001b[39m=\u001b[39m [Population\u001b[39m.\u001b[39;49mfrom_file(popfile\u001b[39m.\u001b[39;49mreplace(\u001b[39m\"\u001b[39;49m\u001b[39mHip_Hop\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mHip-Hop\u001b[39;49m\u001b[39m\"\u001b[39;49m)) \u001b[39mfor\u001b[39;00m popfile \u001b[39min\u001b[39;00m popfiles]\n\u001b[0;32m     19\u001b[0m \u001b[39m# songs = [librosa.load(soundfile)[0] for soundfile in soundfiles]\u001b[39;00m\n\u001b[0;32m     20\u001b[0m sr \u001b[39m=\u001b[39m \u001b[39m22050\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\justi\\coding\\Uni\\MA\\evoaudio\\population.py:171\u001b[0m, in \u001b[0;36mPopulation.from_file\u001b[1;34m(cls, filename, expand, sample_lib)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Loads a population from a pickled file.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39m    The loaded population contained in the given file.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fp:\n\u001b[1;32m--> 171\u001b[0m     obj \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(fp)\n\u001b[0;32m    172\u001b[0m     \u001b[39mif\u001b[39;00m expand \u001b[39mand\u001b[39;00m sample_lib \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m         obj\u001b[39m.\u001b[39m_expand(sample_lib)\n",
      "File \u001b[1;32mc:\\Users\\justi\\mambaforge-pypy3\\envs\\MA\\lib\\enum.py:359\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[1;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[39m    classes/types should always be True.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, value, names\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, module\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, qualname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m    360\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[39m    Either returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39m    `type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[39mif\u001b[39;00m names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# simple value lookup\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "# Load populations, Load Songs\n",
    "all_popfiles = glob(\"./experiments/1517_artists/300_1_10000_0.05_5_10_1_20_0.9954_15_1sec/*.pkl\")\n",
    "popfiles = [file.replace(\"Hip-Hop\", \"Hip_Hop\") for file in all_popfiles if \"500gens\" not in file and \".logger\" not in file]\n",
    "labels = [os.path.basename(file.split(\"-\")[0]) for file in popfiles]\n",
    "songnames = [file.split(\"-\", 1)[1].split(\".\")[0] for file in popfiles]\n",
    "# all_soundfiles = glob(\"./audio/1517-Artists/**/*.mp3\", recursive=True)\n",
    "# soundfiles = []\n",
    "# for name in songnames:\n",
    "#     for file in all_soundfiles:\n",
    "#         if name in file:\n",
    "#             soundfiles.append(file)\n",
    "#             break\n",
    "# lib = SampleLibrary()\n",
    "pops = [Population.from_file(popfile.replace(\"Hip_Hop\", \"Hip-Hop\")) for popfile in popfiles]\n",
    "# songs = [librosa.load(soundfile)[0] for soundfile in soundfiles]\n",
    "sr = 22050\n",
    "\n",
    "# Separate the archive into 10s and 3s chunks\n",
    "\n",
    "# Create feature vectors for pops for windows of 10s and 3s across the song\n",
    "def pop_to_window_vectors(pop:Population, song_length:int, window_length_s:int, lib:SampleLibrary, sr:int=22050):\n",
    "    window_length = sr*window_length_s\n",
    "    window_indices = list(range(0, song_length, window_length))\n",
    "    all_features = [extract_features_for_window(\n",
    "            pop=pop, lib=lib, \n",
    "            window_start=window_idx, \n",
    "            window_end=min(window_idx+window_length, song_length)) \n",
    "        for window_idx in window_indices]\n",
    "    return np.array(all_features)\n",
    "\n",
    "# features_10s = pop_to_window_vectors(pop=pop, song_length=len(song), window_length_s=10, lib=lib, sr=sr)\n",
    "# features_3s = pop_to_window_vectors(pop=pop, song_length=len(song), window_length_s=3, lib=lib, sr=sr)\n",
    "\n",
    "# Divide songs into 4s windows with 2s overlap\n",
    "def get_features_for_time_window(features, feature_window_length_s, window_start_s, window_end_s):\n",
    "    # Calc in which window we start\n",
    "    start_idx = window_start_s // feature_window_length_s\n",
    "    # Calc in which window we end\n",
    "    end_idx = window_end_s // feature_window_length_s\n",
    "    # Get all features in between\n",
    "    window_features = features[start_idx:(end_idx+1)]\n",
    "    # Calc mean between feature vectors\n",
    "    return np.mean(window_features, axis=0)\n",
    "\n",
    "# song_feature_matrix = np.array([np.concatenate([\n",
    "#     get_features_for_time_window(features_10s, 10, i, i+4), \n",
    "#     get_features_for_time_window(features_3s, 3, i, i+4)]) \n",
    "#     for i in range(0, len(song), sr*2)])\n",
    "\n",
    "# # Create train and test sets\n",
    "# X = song_feature_matrix\n",
    "# y = np.repeat(labels[0], len(X))\n",
    "# # Train Random Forests with 100 trees\n",
    "# song_feature_matrix.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Generation Wrapper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_to_window_vectors(pop:Population, song_length:int, window_length_s:int, lib:SampleLibrary, sr:int=22050):\n",
    "    window_length = sr*window_length_s\n",
    "    window_indices = list(range(0, song_length, window_length))\n",
    "    all_features = [extract_features_for_window(\n",
    "            pop=pop, lib=lib, \n",
    "            window_start=window_idx, \n",
    "            window_end=min(window_idx+window_length, song_length)) \n",
    "        for window_idx in window_indices]\n",
    "    return np.array(all_features)\n",
    "\n",
    "def get_features_for_time_window(features, feature_window_length_s, window_start_s, window_end_s):\n",
    "    # Calc in which window we start\n",
    "    start_idx = window_start_s // feature_window_length_s\n",
    "    # Calc in which window we end\n",
    "    end_idx = window_end_s // feature_window_length_s\n",
    "    # Get all features in between\n",
    "    window_features = features[start_idx:(end_idx+1)]\n",
    "    # Calc mean between feature vectors\n",
    "    return np.mean(window_features, axis=0)\n",
    "\n",
    "def get_xy_for_pop(pop:Population, label:str, song_length:int, sr:int=22050):\n",
    "    features_10s = pop_to_window_vectors(pop=pop, song_length=song_length, window_length_s=10, lib=lib, sr=sr)\n",
    "    features_3s = pop_to_window_vectors(pop=pop, song_length=song_length, window_length_s=3, lib=lib, sr=sr)\n",
    "    song_feature_matrix = np.array([np.concatenate([\n",
    "        get_features_for_time_window(features_10s, 10, i, i+4), \n",
    "        get_features_for_time_window(features_3s, 3, i, i+4)]) \n",
    "        for i in range(0, int(song_length/sr), 2)])\n",
    "    return song_feature_matrix, np.repeat(label, len(song_feature_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Population files and correct song labels\n",
    "# all_popfiles = glob(\"./experiments/1517_artists/300_1_10000_0.05_5_10_1_20_0.9954_15_1sec/*.pkl\")\n",
    "# Initial Populations (0 Generations)\n",
    "all_popfiles = glob(\"./experiments/1517_artists/300_1_0_0.05_5_10_1_20_0.9954_15_1sec/*.pkl\")\n",
    "# For 500 Generations\n",
    "# popfiles = [file.replace(\"\\\\Hip_Hop-\", \"\\\\Hip-Hop-\") for file in all_popfiles if \"500gens\" in file and \".logger\" not in file]\n",
    "# For 10k Generations\n",
    "popfiles = [file.replace(\"\\\\Hip_Hop-\", \"\\\\Hip-Hop-\") for file in all_popfiles if \"500gens\" not in file and \".logger\" not in file]\n",
    "labels = [os.path.basename(file.split(\"-\")[0]) for file in popfiles]\n",
    "songnames = [file.split(\"-\", 1)[1].split(\".\")[0] for file in popfiles]\n",
    "sr = 22050\n",
    "# Split songs into train/test sets so that we can later get errors per genre label\n",
    "# Get songs per label\n",
    "songs_per_label = {label: 0 for label in set(labels)}\n",
    "for i in range(len(popfiles)):\n",
    "    songs_per_label[labels[i]] += 1\n",
    "# Shuffle\n",
    "rnd_idx = list(range(len(popfiles)))\n",
    "np.random.shuffle(rnd_idx)\n",
    "# 80/20 Train/test split\n",
    "popfiles_train = np.take(popfiles, rnd_idx[:int(0.8*len(rnd_idx))])\n",
    "popfiles_test = np.take(popfiles, rnd_idx[int(0.8*len(rnd_idx)):])\n",
    "labels_train = np.take(labels, rnd_idx[:int(0.8*len(rnd_idx))])\n",
    "labels_test = np.take(labels, rnd_idx[int(0.8*len(rnd_idx)):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2449/2449 [02:35<00:00, 15.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build X, y\n",
    "x_train = []\n",
    "y_train = []\n",
    "# Train Set\n",
    "for i, popfile in enumerate(tqdm(popfiles_train)):\n",
    "    pop = Population.from_file(popfile, expand=False)\n",
    "    label = labels_train[i]\n",
    "    song_length = max(pop.archive.keys()) + 1\n",
    "    x, y_labels = get_xy_for_pop(pop=pop, label=label, song_length=song_length, sr=sr)\n",
    "    x_train.append(x)\n",
    "    y_train.append(y_labels)\n",
    "\n",
    "x_train = np.concatenate(x_train)\n",
    "y_train = np.concatenate(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=7, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=7, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=7, random_state=0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=0)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 613/613 [00:39<00:00, 15.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split Test Set by Song, Label\n",
    "x_test_by_song = []\n",
    "y_test_by_song = []\n",
    "for i, popfile in enumerate(tqdm(popfiles_test)):\n",
    "    pop = Population.from_file(popfile, expand=False)\n",
    "    label = labels_test[i]\n",
    "    song_length = max(pop.archive.keys()) + 1\n",
    "    x, y_labels = get_xy_for_pop(pop=pop, label=label, song_length=song_length, sr=sr)\n",
    "    x_test_by_song.append(x)\n",
    "    y_test_by_song.append(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority Voting across the windows of a piece\n",
    "def majority_voting(votes):\n",
    "    counts = {vote: 0 for vote in set(votes)}\n",
    "    for vote in votes:\n",
    "        counts[vote] += 1\n",
    "    return list(counts.keys())[np.argmax(list(counts.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 613/613 [00:05<00:00, 120.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate errors for entire songs, per label\n",
    "preds_per_label = {label: [[],[]] for label in labels}\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for i, song_x in enumerate(tqdm(x_test_by_song)):\n",
    "    song_y = y_test_by_song[i]\n",
    "    song_label = y_test_by_song[i][0]\n",
    "    votes = clf.predict(song_x)\n",
    "    vote_winner = majority_voting(votes)\n",
    "    preds_per_label[song_label][0].append(song_label)\n",
    "    preds_per_label[song_label][1].append(vote_winner)\n",
    "    y_true.append(song_label)\n",
    "    y_pred.append(vote_winner)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11141945124282034"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "f1_score(y_true, y_pred, average='micro', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Alternative_and_Punk': 0.157651376146789,\n",
       "  'Blues': 0.030862592110966626,\n",
       "  'Childrenss': 0.0,\n",
       "  'Classical': 0.4247817327065144,\n",
       "  'Comedy_and_Spoken_Word': 0.0,\n",
       "  'Country': 0.0,\n",
       "  'Easy_Listening_and_Vocals': 0.033690360272638754,\n",
       "  'Electronic_and_Dance': 0.3972667742241625,\n",
       "  'Folk': 0.3279569892473118,\n",
       "  'Hip': 0.0,\n",
       "  'Jazz': 0.3747688114474837,\n",
       "  'Latin': 0.0,\n",
       "  'New_Age': 0.12556122060725974,\n",
       "  'Reggae': 0.12920721008135266,\n",
       "  'Religious': 0.0,\n",
       "  'Rock_and_Pop': 0.1076120959332638,\n",
       "  'R_and_B_and_Soul': 0.024248584289240597,\n",
       "  'Soundtracks_and_More': 0.0,\n",
       "  'World': 0.0},\n",
       " {'Alternative_and_Punk': 0.15384615384615385,\n",
       "  'Blues': 0.030303030303030304,\n",
       "  'Childrenss': 0.0,\n",
       "  'Classical': 0.4782608695652174,\n",
       "  'Comedy_and_Spoken_Word': 0.0,\n",
       "  'Country': 0.0,\n",
       "  'Easy_Listening_and_Vocals': 0.03225806451612903,\n",
       "  'Electronic_and_Dance': 0.40625,\n",
       "  'Folk': 0.3157894736842105,\n",
       "  'Hip': 0.0,\n",
       "  'Jazz': 0.36666666666666664,\n",
       "  'Latin': 0.0,\n",
       "  'New_Age': 0.12195121951219512,\n",
       "  'Reggae': 0.13157894736842105,\n",
       "  'Religious': 0.0,\n",
       "  'Rock_and_Pop': 0.10714285714285714,\n",
       "  'R_and_B_and_Soul': 0.024390243902439025,\n",
       "  'Soundtracks_and_More': 0.0,\n",
       "  'World': 0.0},\n",
       " {'Alternative_and_Punk': 0.16164960866947622,\n",
       "  'Blues': 0.03144320791379615,\n",
       "  'Childrenss': 0.0,\n",
       "  'Classical': 0.38205980066445183,\n",
       "  'Comedy_and_Spoken_Word': 0.0,\n",
       "  'Country': 0.0,\n",
       "  'Easy_Listening_and_Vocals': 0.03525575708171999,\n",
       "  'Electronic_and_Dance': 0.38867223769730735,\n",
       "  'Folk': 0.34109972041006525,\n",
       "  'Hip': 0.0,\n",
       "  'Jazz': 0.3832371092972327,\n",
       "  'Latin': 0.0,\n",
       "  'New_Age': 0.12939146800501883,\n",
       "  'Reggae': 0.12691946098401755,\n",
       "  'Religious': 0.0,\n",
       "  'Rock_and_Pop': 0.1080854629241726,\n",
       "  'R_and_B_and_Soul': 0.02410856070448968,\n",
       "  'Soundtracks_and_More': 0.0,\n",
       "  'World': 0.0})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 per label\n",
    "f1_per_label = dict()\n",
    "recall_per_label = dict()\n",
    "precision_per_label = dict()\n",
    "for label in preds_per_label:\n",
    "    y_true, y_pred = preds_per_label[label]\n",
    "    f1_per_label[label] = f1_score(y_true, y_pred, average='micro', labels=labels)\n",
    "    recall_per_label[label] = recall_score(y_true, y_pred, average='micro', labels=labels)\n",
    "    precision_per_label[label] = precision_score(y_true, y_pred, average='micro', labels=labels)\n",
    "f1_per_label, recall_per_label, precision_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3067/3067 [00:26<00:00, 115.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#calc fitnesses\n",
    "label_fitnesses = {label: [] for label in set(labels)}\n",
    "discarded = []\n",
    "for i, popfile in enumerate(tqdm(popfiles)):\n",
    "    pop = Population.from_file(popfile, expand=False)\n",
    "    fitnesses = [record.fitness for record in pop.archive.values()]\n",
    "    mean_fitness = np.mean(fitnesses)\n",
    "    if mean_fitness < 10**4:\n",
    "        label_fitnesses[labels[i]].append(mean_fitness)\n",
    "    else:\n",
    "        discarded.append(mean_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country': 35.994076656258535,\n",
       " 'World': 3.7500810689524666,\n",
       " 'Jazz': 69.67296040641808,\n",
       " 'Soundtracks_and_More': 2.0275951983369707,\n",
       " 'Blues': 12.86501812049024,\n",
       " 'Classical': 4.618699124432691,\n",
       " 'Folk': 10.717715124340243,\n",
       " 'R_and_B_and_Soul': 63.33962704998383,\n",
       " 'Latin': 8.294410389258113,\n",
       " 'Reggae': 64.06526524509258,\n",
       " 'Religious': 8.798272774565245,\n",
       " 'Hip': 2.15256387016661,\n",
       " 'Easy_Listening_and_Vocals': 22.836141936281187,\n",
       " 'Electronic_and_Dance': 26.342626401274977,\n",
       " 'Alternative_and_Punk': 6.926078724505477,\n",
       " 'New_Age': 51.7937330441161,\n",
       " 'Childrenss': 3.484386581495564,\n",
       " 'Comedy_and_Spoken_Word': 2.855394249713554,\n",
       " 'Rock_and_Pop': 25.383478351013228}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_label_fitnesses = {label: np.mean(label_fitnesses[label]) for label in label_fitnesses}\n",
    "mean_label_fitnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Fitness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alternative_and_Punk</th>\n",
       "      <td>0.157651</td>\n",
       "      <td>0.161650</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>5.443492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blues</th>\n",
       "      <td>0.030863</td>\n",
       "      <td>0.031443</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>70.618356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Childrenss</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.959346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classical</th>\n",
       "      <td>0.424782</td>\n",
       "      <td>0.382060</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>4.803002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy_and_Spoken_Word</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.320552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.933176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Easy_Listening_and_Vocals</th>\n",
       "      <td>0.033690</td>\n",
       "      <td>0.035256</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>34.425130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electronic_and_Dance</th>\n",
       "      <td>0.397267</td>\n",
       "      <td>0.388672</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>22.792770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Folk</th>\n",
       "      <td>0.327957</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>58.211149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hip</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.107658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jazz</th>\n",
       "      <td>0.374769</td>\n",
       "      <td>0.383237</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>55.408273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.561431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New_Age</th>\n",
       "      <td>0.125561</td>\n",
       "      <td>0.129391</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>53.493158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reggae</th>\n",
       "      <td>0.129207</td>\n",
       "      <td>0.126919</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>44.357877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Religious</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.439374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock_and_Pop</th>\n",
       "      <td>0.107612</td>\n",
       "      <td>0.108085</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>33.178193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_and_B_and_Soul</th>\n",
       "      <td>0.024249</td>\n",
       "      <td>0.024109</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>47.914217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soundtracks_and_More</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.608475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>World</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.072545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           F1_Score  Precision    Recall    Fitness\n",
       "Alternative_and_Punk       0.157651   0.161650  0.153846   5.443492\n",
       "Blues                      0.030863   0.031443  0.030303  70.618356\n",
       "Childrenss                 0.000000   0.000000  0.000000   2.959346\n",
       "Classical                  0.424782   0.382060  0.478261   4.803002\n",
       "Comedy_and_Spoken_Word     0.000000   0.000000  0.000000   2.320552\n",
       "Country                    0.000000   0.000000  0.000000  54.933176\n",
       "Easy_Listening_and_Vocals  0.033690   0.035256  0.032258  34.425130\n",
       "Electronic_and_Dance       0.397267   0.388672  0.406250  22.792770\n",
       "Folk                       0.327957   0.341100  0.315789  58.211149\n",
       "Hip                        0.000000   0.000000  0.000000   2.107658\n",
       "Jazz                       0.374769   0.383237  0.366667  55.408273\n",
       "Latin                      0.000000   0.000000  0.000000  55.561431\n",
       "New_Age                    0.125561   0.129391  0.121951  53.493158\n",
       "Reggae                     0.129207   0.126919  0.131579  44.357877\n",
       "Religious                  0.000000   0.000000  0.000000   8.439374\n",
       "Rock_and_Pop               0.107612   0.108085  0.107143  33.178193\n",
       "R_and_B_and_Soul           0.024249   0.024109  0.024390  47.914217\n",
       "Soundtracks_and_More       0.000000   0.000000  0.000000   1.608475\n",
       "World                      0.000000   0.000000  0.000000   3.072545"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(f1_per_label.values()), index=list(f1_per_label.keys()), columns=[\"F1_Score\"])\n",
    "df[\"Precision\"] = list(precision_per_label.values())\n",
    "df[\"Recall\"] = list(recall_per_label.values())\n",
    "df[\"Fitness\"] = mean_label_fitnesses\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justi\\AppData\\Local\\Temp\\ipykernel_9312\\2575103615.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.round(3).to_latex(buf=fp, index=False)\n"
     ]
    }
   ],
   "source": [
    "with open(\"./table500.tex\", \"w\") as fp:\n",
    "    df.round(3).to_latex(buf=fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.121</td>\n",
       "      <td>6.926 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.865 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.484 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.575</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.625</td>\n",
       "      <td>4.618 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.855 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>35.994 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.836 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.382</td>\n",
       "      <td>26.342 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.717 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.038</td>\n",
       "      <td>2.152 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.559</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.548</td>\n",
       "      <td>69.672 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.294 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.267</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.258</td>\n",
       "      <td>51.793 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.109</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.111</td>\n",
       "      <td>64.065 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.798 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.143</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.142</td>\n",
       "      <td>25.383 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.080</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.081</td>\n",
       "      <td>63.339 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.027 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.750 \\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\bottomrule</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\end{tabular}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0      1      2           3\n",
       "0          0.125   0.129  0.121    6.926 \\\\\n",
       "1          0.000   0.000  0.000   12.865 \\\\\n",
       "2          0.000   0.000  0.000    3.484 \\\\\n",
       "3          0.575   0.532  0.625    4.618 \\\\\n",
       "4          0.000   0.000  0.000    2.855 \\\\\n",
       "5          0.000   0.000  0.000   35.994 \\\\\n",
       "6          0.000   0.000  0.000   22.836 \\\\\n",
       "7          0.375   0.368  0.382   26.342 \\\\\n",
       "8          0.000   0.000  0.000   10.717 \\\\\n",
       "9          0.036   0.034  0.038    2.152 \\\\\n",
       "10         0.559   0.572  0.548   69.672 \\\\\n",
       "11         0.000   0.000  0.000    8.294 \\\\\n",
       "12         0.267   0.278  0.258   51.793 \\\\\n",
       "13         0.109   0.107  0.111   64.065 \\\\\n",
       "14         0.000   0.000  0.000    8.798 \\\\\n",
       "15         0.143   0.144  0.142   25.383 \\\\\n",
       "16         0.080   0.080  0.081   63.339 \\\\\n",
       "17         0.000   0.000  0.000    2.027 \\\\\n",
       "18         0.000   0.000  0.000    3.750 \\\\\n",
       "19    \\bottomrule    NaN    NaN        None\n",
       "20  \\end{tabular}    NaN    NaN        None"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all tables\n",
    "df = pd.read_csv('table0.tex',\n",
    "                 sep='&',\n",
    "                 header=None,\n",
    "                 skiprows=4,\n",
    "                 skipfooter=5,\n",
    "                 engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alternative_and_Punk': 0.8536585365853658,\n",
       " 'Blues': 1.0,\n",
       " 'Childrenss': 1.0,\n",
       " 'Classical': 0.2916666666666667,\n",
       " 'Comedy_and_Spoken_Word': 0.9473684210526315,\n",
       " 'Country': 1.0,\n",
       " 'Easy_Listening_and_Vocals': 0.9696969696969697,\n",
       " 'Electronic_and_Dance': 0.6764705882352942,\n",
       " 'Folk': 1.0,\n",
       " 'Hip': 0.9615384615384616,\n",
       " 'Jazz': 0.45161290322580644,\n",
       " 'Latin': 1.0,\n",
       " 'New_Age': 0.7419354838709677,\n",
       " 'Reggae': 0.9166666666666666,\n",
       " 'Religious': 1.0,\n",
       " 'Rock_and_Pop': 0.8857142857142857,\n",
       " 'R_and_B_and_Soul': 0.8108108108108109,\n",
       " 'Soundtracks_and_More': 1.0,\n",
       " 'World': 1.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_errors_per_label = {label: np.mean(errors) for label, errors in errors_per_label.items()}\n",
    "mean_errors_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8687968312665223"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_error_majority_votes = np.mean(list(mean_errors_per_label.values()))\n",
    "mean_error_majority_votes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errors per window, irrespective of song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8738395894597244"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.concatenate(x_test_by_song)\n",
    "y_test = np.concatenate(y_test_by_song)\n",
    "predictions = clf.predict(x_test)\n",
    "errors = [1*(not predictions[i] == y_test[i]) for i in range(len(predictions))]\n",
    "np.mean(errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e64d2645d10406c485d9857eaab5d37f8c8efad32a47710fb4de5b20809a4099"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
