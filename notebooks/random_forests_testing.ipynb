{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\coding\\Uni\\MA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\miniconda3\\envs\\ma\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from population import Population\n",
    "from sample_library import SampleLibrary\n",
    "from feature_extraction import extract_features_for_window, extract_features_for_windows\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population to feature vector of shape (n_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The following statistics are proposed as approximative features.  \n",
    "For each instrument and each onset in the approximated\n",
    "music track, we save the smallest distance between the best\n",
    "candidate mixture which contains this instrument and the onset\n",
    "to approximate.  \n",
    "(pop.best_collections_per_onset)  \n",
    "  \n",
    "These smallest distances are kept during the\n",
    "complete evolutionary loop in an archive and do not represent\n",
    "the final population only. (TODO!) \n",
    "    \n",
    "Then, we estimate the mean, the\n",
    "minimum, and the maximum values for each of 51 instrument\n",
    "and 88 theoretically possible pitches for two different analysis\n",
    "frames of 10s and 3s. Additionally, we sort the recognised\n",
    "instruments based on the smallest distances, and assign ranks\n",
    "to corresponding approximative features, e.g., value of “rang\n",
    "of acoustic guitar” = 1 means that acoustic guitar had the\n",
    "smallest mean distance between approximations with this\n",
    "instrument and unknown onsets in the analysis frame. This\n",
    "leads to an overall number of feature dimensions equal to\n",
    "(51 · 3 + 88 · 3 + 51) · 2 = 936.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading samples: 100%|██████████| 6478/6478 [00:08<00:00, 777.86it/s] \n"
     ]
    }
   ],
   "source": [
    "pop = Population.from_file(\"test.pkl\")\n",
    "target, sr = librosa.load(librosa.ex('nutcracker'), duration=30)\n",
    "lib = SampleLibrary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 features generated from 50 instruments and 89 pitches.\n"
     ]
    }
   ],
   "source": [
    "## Choose two different analysis frames of 10s and 3s\n",
    "end_offset = 10 * sr\n",
    "possible_onsets = len(target) - end_offset\n",
    "window_start = np.random.randint(low=0, high=possible_onsets)\n",
    "window_end = window_start + end_offset\n",
    "\n",
    "## Grab the onsets in those windows, and the associated best records from the population\n",
    "relevant_collections = [collection for collection in pop.best_collections_per_onset.values() if collection.onset in range(window_start, window_end)]\n",
    "\n",
    "## For each window separately, calculate the maximum, minimum, and mean fitnesses for each occasion of\n",
    "## An instrument\n",
    "instrument_occurrences_fitness = dict()\n",
    "## A pitch\n",
    "pitch_occurrences_fitness = dict()\n",
    "\n",
    "for collection in relevant_collections:\n",
    "    for sample in collection.samples:\n",
    "        if sample.instrument in instrument_occurrences_fitness:\n",
    "            instrument_occurrences_fitness[sample.instrument].append(collection.fitness)\n",
    "        else:\n",
    "            instrument_occurrences_fitness[sample.instrument] = [collection.fitness]\n",
    "        if sample.pitch in pitch_occurrences_fitness:\n",
    "            pitch_occurrences_fitness[sample.pitch].append(collection.fitness)\n",
    "        else:\n",
    "            pitch_occurrences_fitness[sample.pitch] = [collection.fitness]\n",
    "\n",
    "# print(instrument_occurrences_fitness)\n",
    "# print(pitch_occurrences_fitness)\n",
    "\n",
    "instrument_min = {instrument: np.min(instrument_occurrences_fitness[instrument]) for instrument in instrument_occurrences_fitness}\n",
    "instrument_max = {instrument: np.max(instrument_occurrences_fitness[instrument]) for instrument in instrument_occurrences_fitness}\n",
    "instrument_mean = {instrument: np.mean(instrument_occurrences_fitness[instrument]) for instrument in instrument_occurrences_fitness}\n",
    "\n",
    "pitch_min = {pitch: np.min(pitch_occurrences_fitness[pitch]) for pitch in pitch_occurrences_fitness}\n",
    "pitch_max = {pitch: np.max(pitch_occurrences_fitness[pitch]) for pitch in pitch_occurrences_fitness}\n",
    "pitch_mean = {pitch: np.mean(pitch_occurrences_fitness[pitch]) for pitch in pitch_occurrences_fitness}\n",
    "\n",
    "## Finally, give each instrument a rank from 1 to n_instruments, based on their mean distances (smallest = rank 1, highest = rank n_instruments)\n",
    "# instrument_sort = np.argsort([instrument_mean[instrument] for instrument in instrument_mean])\n",
    "instrument_sort = {k: v for k, v in sorted(instrument_mean.items(), key=lambda item: item[1])}\n",
    "instrument_ranks = {instrument: i + 1 for i, instrument in enumerate(instrument_sort)}\n",
    "\n",
    "# Create feature vector\n",
    "instrument_features = []\n",
    "for instrument_info in lib.instruments:\n",
    "    instr_name = instrument_info.name\n",
    "    if instr_name in instrument_ranks:\n",
    "        instrument_features.append([instrument_min[instr_name], instrument_mean[instr_name], instrument_max[instr_name], instrument_ranks[instr_name]])\n",
    "    else:\n",
    "        instrument_features.append([np.inf, np.inf, np.inf, np.inf])\n",
    "pitch_features = []\n",
    "for pitch in lib.pitches:\n",
    "    if pitch in pitch_min:\n",
    "        pitch_features.append([pitch_min[pitch], pitch_mean[pitch], pitch_max[pitch]])\n",
    "    else:\n",
    "        pitch_features.append([np.inf, np.inf, np.inf])\n",
    "flat_instr_features = np.array(instrument_features).flatten()\n",
    "flat_pitch_features = np.array(pitch_features).flatten()\n",
    "features = np.concatenate((flat_instr_features, flat_pitch_features))\n",
    "print(f\"{len(features)} features generated from {len(lib.instruments)} instruments and {len(lib.pitches)} pitches.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 features generated from 50 instruments and 89 pitches.\n"
     ]
    }
   ],
   "source": [
    "end_offset = 10 * sr\n",
    "possible_onsets = len(target) - end_offset\n",
    "window_start = np.random.randint(low=0, high=possible_onsets)\n",
    "window_end = window_start + end_offset\n",
    "features = extract_features_for_window(pop, lib, window_start, window_end)\n",
    "print(f\"{len(features)} features generated from {len(lib.instruments)} instruments and {len(lib.pitches)} pitches.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934 features generated from 50 instruments and 89 pitches.\n"
     ]
    }
   ],
   "source": [
    "features = extract_features_for_windows(pop=pop, lib=lib, window_lengths=[3, 10], n_total_samples=len(target), sr=sr)\n",
    "print(f\"{len(features)} features generated from {len(lib.instruments)} instruments and {len(lib.pitches)} pitches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X, y)\n",
    "print(clf.predict([[0, 0, 0, 0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e64d2645d10406c485d9857eaab5d37f8c8efad32a47710fb4de5b20809a4099"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
